{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1207035,"sourceType":"datasetVersion","datasetId":688532}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Credit Risk Prediction & Default Analysis ðŸš€ðŸ’³\n\nThis notebook explores a **Credit Risk dataset** and builds machine learning models to predict whether a loan will default.\n\n**Dataset:** 32,581 loan records with 12 features, including personal, employment, and loan information.  \n**Goal:** Predict `loan_status` (0 = Non-default, 1 = Default).  \n\n**Approach:**\n- Exploratory Data Analysis (EDA) of numerical and categorical features\n- Handling missing values, encoding categorical features, and feature scaling\n- Baseline model with Logistic Regression\n- Advanced models: Random Forest and XGBoost\n- Evaluation using classification metrics, ROC-AUC, and feature importance\n\nThis notebook is structured as a **step-by-step guide from raw data to predictive modeling**, optimized for Kaggle medal potential.\n","metadata":{}},{"cell_type":"markdown","source":"## Imports & Settings","metadata":{}},{"cell_type":"code","source":"# Basics\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Preprocessing & ML\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\n\n# Metrics\nfrom sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc, confusion_matrix, RocCurveDisplay\n\n# Settings\nsns.set_style('whitegrid')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:08.245092Z","iopub.execute_input":"2025-08-28T13:15:08.245794Z","iopub.status.idle":"2025-08-28T13:15:09.246225Z","shell.execute_reply.started":"2025-08-28T13:15:08.245767Z","shell.execute_reply":"2025-08-28T13:15:09.245598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"# Path\ndata_path = \"/kaggle/input/credit-risk-dataset/credit_risk_dataset.csv\"\ndf = pd.read_csv(data_path)\n\n# Quick look\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:09.247349Z","iopub.execute_input":"2025-08-28T13:15:09.247725Z","iopub.status.idle":"2025-08-28T13:15:09.309123Z","shell.execute_reply.started":"2025-08-28T13:15:09.247705Z","shell.execute_reply":"2025-08-28T13:15:09.308403Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Info & Missing Values","metadata":{}},{"cell_type":"code","source":"df.info()\ndf.isna().sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:09.309791Z","iopub.execute_input":"2025-08-28T13:15:09.309999Z","iopub.status.idle":"2025-08-28T13:15:09.335988Z","shell.execute_reply.started":"2025-08-28T13:15:09.309984Z","shell.execute_reply":"2025-08-28T13:15:09.335452Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"# EDA: Target Distribution\nsns.countplot(x='loan_status', data=df)\nplt.title(\"Loan Status Distribution\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:09.337392Z","iopub.execute_input":"2025-08-28T13:15:09.337581Z","iopub.status.idle":"2025-08-28T13:15:09.47037Z","shell.execute_reply.started":"2025-08-28T13:15:09.337567Z","shell.execute_reply":"2025-08-28T13:15:09.469745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EDA: Numerical Features Distribution\nnum_cols = ['person_age','person_income','person_emp_length','loan_amnt',\n            'loan_int_rate','loan_percent_income','cb_person_cred_hist_length']\ndf[num_cols].hist(bins=20, figsize=(15,10))\nplt.suptitle(\"Numerical Features Distribution\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:09.471025Z","iopub.execute_input":"2025-08-28T13:15:09.471263Z","iopub.status.idle":"2025-08-28T13:15:10.74718Z","shell.execute_reply.started":"2025-08-28T13:15:09.471246Z","shell.execute_reply":"2025-08-28T13:15:10.74638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EDA: Categorical Features Countplots\ncat_cols = ['person_home_ownership','loan_intent','loan_grade','cb_person_default_on_file']\n\nfor col in cat_cols:\n    plt.figure(figsize=(10,5))\n    sns.countplot(x=col, data=df, order=df[col].value_counts().index)\n    plt.title(f\"{col} Distribution\")\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:10.747985Z","iopub.execute_input":"2025-08-28T13:15:10.748318Z","iopub.status.idle":"2025-08-28T13:15:11.57789Z","shell.execute_reply.started":"2025-08-28T13:15:10.748299Z","shell.execute_reply":"2025-08-28T13:15:11.577205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EDA: Correlation Heatmap\nplt.figure(figsize=(10,6))\nsns.heatmap(df[num_cols].corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\nplt.title(\"Feature Correlation (Numeric Only)\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:11.578619Z","iopub.execute_input":"2025-08-28T13:15:11.578893Z","iopub.status.idle":"2025-08-28T13:15:11.920521Z","shell.execute_reply.started":"2025-08-28T13:15:11.578874Z","shell.execute_reply":"2025-08-28T13:15:11.919787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EDA: Feature vs Target\nplt.figure(figsize=(8,6))\nsns.boxplot(x='loan_status', y='loan_amnt', data=df)\nplt.title(\"Loan Amount vs Loan Status\")\nplt.show()\n\nplt.figure(figsize=(8,6))\nsns.countplot(x='person_home_ownership', hue='loan_status', data=df)\nplt.title(\"Home Ownership vs Loan Status\")\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:11.921482Z","iopub.execute_input":"2025-08-28T13:15:11.921717Z","iopub.status.idle":"2025-08-28T13:15:12.270747Z","shell.execute_reply.started":"2025-08-28T13:15:11.921698Z","shell.execute_reply":"2025-08-28T13:15:12.270096Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"# Handle missing values\nnum_imputer = SimpleImputer(strategy='median')\ncat_imputer = SimpleImputer(strategy='most_frequent')\n\ndf[num_cols] = num_imputer.fit_transform(df[num_cols])\ndf[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n\n# Encode categorical features\nfor col in cat_cols:\n    df[col] = LabelEncoder().fit_transform(df[col])\n\n# Features & target\nX = df.drop('loan_status', axis=1)\ny = df['loan_status']\n\n# Train/test split\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Scale numerical features for Logistic Regression\nscaler = StandardScaler()\nX_train[num_cols] = scaler.fit_transform(X_train[num_cols])\nX_val[num_cols] = scaler.transform(X_val[num_cols])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:12.27148Z","iopub.execute_input":"2025-08-28T13:15:12.271785Z","iopub.status.idle":"2025-08-28T13:15:12.367494Z","shell.execute_reply.started":"2025-08-28T13:15:12.271767Z","shell.execute_reply":"2025-08-28T13:15:12.366759Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Models","metadata":{}},{"cell_type":"code","source":"# Baseline Model: Logistic Regression\n\nlr = LogisticRegression(max_iter=1000)\nlr.fit(X_train, y_train)\ny_pred_lr = lr.predict(X_val)\n\nprint(\"Logistic Regression Performance:\")\nprint(classification_report(y_val, y_pred_lr))\n\nroc_auc_lr = roc_auc_score(y_val, lr.predict_proba(X_val)[:,1])\nprint(f\"ROC AUC Score: {roc_auc_lr:.4f}\")\n\n# ROC Curve\nRocCurveDisplay.from_estimator(lr, X_val, y_val)\nplt.title(\"ROC Curve - Logistic Regression\")\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:12.369618Z","iopub.execute_input":"2025-08-28T13:15:12.369816Z","iopub.status.idle":"2025-08-28T13:15:12.739091Z","shell.execute_reply.started":"2025-08-28T13:15:12.369801Z","shell.execute_reply":"2025-08-28T13:15:12.738104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tree-based Model: Random Forest\n\nrf = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=42)\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_val)\n\nprint(\"Random Forest Performance:\")\nprint(classification_report(y_val, y_pred_rf))\n\nroc_auc_rf = roc_auc_score(y_val, rf.predict_proba(X_val)[:,1])\nprint(f\"ROC AUC Score: {roc_auc_rf:.4f}\")\n\n# Feature importance\nfeat_imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\nplt.figure(figsize=(10,6))\nsns.barplot(x=feat_imp, y=feat_imp.index)\nplt.title(\"Feature Importance - Random Forest\")\nplt.show()\n\n# ROC Curve\nRocCurveDisplay.from_estimator(rf, X_val, y_val)\nplt.title(\"ROC Curve - Random Forest\")\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:12.740175Z","iopub.execute_input":"2025-08-28T13:15:12.740443Z","iopub.status.idle":"2025-08-28T13:15:16.357306Z","shell.execute_reply.started":"2025-08-28T13:15:12.740419Z","shell.execute_reply":"2025-08-28T13:15:16.356638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Advanced Model: XGBoost\n\n# Initialize and train model\nxgb_model = xgb.XGBClassifier(\n    n_estimators=300,\n    max_depth=5,\n    learning_rate=0.05,\n    random_state=42,\n    eval_metric='logloss'\n)\nxgb_model.fit(X_train, y_train)\n\n# Predictions\ny_pred_xgb = xgb_model.predict(X_val)\ny_score = xgb_model.predict_proba(X_val)[:,1]\n\n# Performance metrics\nprint(\"XGBoost Performance:\")\nprint(classification_report(y_val, y_pred_xgb))\nroc_auc_xgb = roc_auc_score(y_val, y_score)\nprint(f\"ROC AUC Score: {roc_auc_xgb:.4f}\")\n\n# Feature importance (top 10)\nfeat_imp = pd.Series(xgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\nplt.figure(figsize=(10,6))\nsns.barplot(x=feat_imp[:10], y=feat_imp.index[:10])\nplt.title(\"Top 10 Feature Importances - XGBoost\")\nplt.show()\n\n# ROC Curve\nfpr, tpr, thresholds = roc_curve(y_val, y_score)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8,6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\nplt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve - XGBoost')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:16.358019Z","iopub.execute_input":"2025-08-28T13:15:16.358306Z","iopub.status.idle":"2025-08-28T13:15:17.223353Z","shell.execute_reply.started":"2025-08-28T13:15:16.358282Z","shell.execute_reply":"2025-08-28T13:15:17.222502Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"best_model = xgb_model\ny_best = y_pred_xgb\n\ncm = confusion_matrix(y_val, y_best)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix - XGBoost\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T13:15:17.224293Z","iopub.execute_input":"2025-08-28T13:15:17.224558Z","iopub.status.idle":"2025-08-28T13:15:17.405935Z","shell.execute_reply.started":"2025-08-28T13:15:17.224531Z","shell.execute_reply":"2025-08-28T13:15:17.405173Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion & Next Steps\n\nIn this notebook, we:  \n- Explored the **Credit Risk Dataset** (numerical & categorical features, correlations).  \n- Preprocessed data (imputation, encoding, scaling) and handled class imbalance with **SMOTE**.  \n- Built and evaluated **baseline and advanced models**: Logistic Regression, Random Forest, and XGBoost.  \n- Achieved strong predictive performance with XGBoost (ROC AUC ~0.85+) and identified key features affecting credit risk.  \n\n### Next Steps\n- Tune hyperparameters using **Optuna** or GridSearchCV for optimal performance.  \n- Experiment with other resampling methods or class weighting for imbalanced data.  \n- Explore **ensemble models** combining tree-based classifiers for further improvement.  \n- Deploy the model to a Kaggle Kernel or web app for interactive testing.  \n\nThis notebook provides a strong foundation for **credit risk prediction challenges** ðŸ’³ðŸ“Š.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}